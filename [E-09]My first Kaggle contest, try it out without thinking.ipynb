{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "confidential-bread",
   "metadata": {},
   "source": [
    "# 9-13. 프로젝트 : This is your playground! Leaderboard를 정복해 주세요!\n",
    "\n",
    "자, 이제 여러분이 직접 다양한 하이퍼 파라미터를 튜닝하며 최적의 조합을 찾아볼 차례입니다.\n",
    "\n",
    "여기서 잠깐, 물론 캐글에서의 성적 또는 모델의 성능을 최대화 하기 위한 방법에는 하이퍼 파라미터 튜닝만 있는 것은 절대 아닙니다.  \n",
    "앞선 과정에서 배웠거나 앞으로 배울 내용에서도 다루듯 모델의 성능을 최적화하는 방법은 매우 많고 지금도 끊임없이 연구되고 있습니다.\n",
    "\n",
    "예를 들면 가장 기본적으로는 데이터를 깊게 탐색하는 **EDA** 과정을 통해 불필요한 피처를 골라내거나 적절하게 피처를 수정하는 등의 피처 엔지니어링을 진행함으로써 데이터를 정제하는 것이 매우 중요합니다. 데이터가 무엇이냐에 따라, 그리고 그 데이터를 어떻게 정제하느냐에 따라 모델의 파라미터를 튜닝하는 것만으로는 절대 얻을 수 없는 성능 향상이 이루어질 수 있습니다.\n",
    "\n",
    "오늘은 이렇게 다양한 방법론 중 하이퍼 파라미터 튜닝에 집중해서 모델의 성능을 최대한 끌어올려보지만, 튜닝은 최적화 방법 중 하나일 뿐이라는 것을 잊지 마세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-marker",
   "metadata": {},
   "source": [
    "### ✓ 튜닝해볼 수 있는 모델 클래스 인자\n",
    "\n",
    "---\n",
    "\n",
    "대표적으로 자주 튜닝하는 lightgbm 라이브러리의 인자는 다음과 같습니다.\n",
    "\n",
    "- `max_depth` : 의사 결정 나무의 깊이, 정수 사용\n",
    "- `learning_rate` : 한 스텝에 이동하는 양을 결정하는 파라미터, 보통 0.0001~0.1 사이의 실수 사용\n",
    "- `n_estimators` : 사용하는 개별 모델의 개수, 보통 50~100 이상의 정수 사용\n",
    "- `num_leaves` : 하나의 LightGBM 트리가 가질 수 있는 최대 잎의 수\n",
    "- `boosting_type` : 부스팅 방식, `gbdt`, `rf` 등의 문자열 입력\n",
    "\n",
    "위에서 저는 `n_estimators`와 `max_depth` 에 대해서만 아주 간단하게 실험했지만, 훨씬 더 다양하게 실험을 하며 최적의 조합을 찾아볼 수 있습니다.  \n",
    "실제로 lightgbm에 넣을 수 있는 인자는 아래 자료들에서 설명하는 것처럼 매우 다양합니다.\n",
    "\n",
    "- [lightGBM / XGBoost 파라미터 설명](http://machinelearningkorea.com/2019/09/29/lightgbm-%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0/)\n",
    "- [Chapter 4. 분류 - LightGBM](https://injo.tistory.com/48)\n",
    "\n",
    "위의 자료 외에도 `lightgbm, xgboost 하이퍼 파라미터 튜닝` 키워드로 검색해보면 다양한 하이퍼 파라미터의 종류를 확인할 수 있습니다.\n",
    "\n",
    "실험 과정에서는 물론 위에서 만들었던 `my_GridSearch()`, `save_submission()` 등의 함수를 사용해도 되고, 혹은 여러분이 원하는 새로운 함수를 만들어서 사용해도 됩니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-demand",
   "metadata": {},
   "source": [
    "### ✓ 시도해볼 수 있는 방법\n",
    "\n",
    "---\n",
    "\n",
    "여러분이 시도해볼 수 있는 방법은 다음과 같은 것들이 있습니다.\n",
    "\n",
    "- 기존에 있는 데이터의 피처를 모델을 보다 잘 표현할 수 있는 형태로 처리하기 (피처 엔지니어링)\n",
    "- LGBMRegressor, XGBRegressor, RandomForestRegressor 세 가지 이상의 다양한 모델에 대해 하이퍼 파라미터 튜닝하기\n",
    "- 다양한 하이퍼 파라미터에 대해 그리드 탐색을 시도해서 최적의 조합을 찾아보기\n",
    "- Baseline 커널에서 활용했던 블렌딩 방법 활용하기\n",
    "\n",
    "물론 이 외에도 좋은 아이디어가 있다면 당연히 시도해보는 것도 좋습니다. 자유롭게 여러 가지 방법을 활용해서 점수를 끌어올려 보세요!  \n",
    "참고로, 진행하면서 도움이 될 수 있는 가장 좋은 자료는 이미 대회를 진행한 사람들이 올려둔 커널입니다.\n",
    "\n",
    "- [https://www.kaggle.com/c/2019-2nd-ml-month-with-kakr/notebooks](https://www.kaggle.com/c/2019-2nd-ml-month-with-kakr/notebooks)\n",
    "\n",
    "아주 다양하게 데이터를 탐색해 본 커널도 있고, 상위권을 달성한 커널은 오늘 다루지 않은 스태킹 앙상블(stacking ensemble) 등의 기법을 활용한 커널을 활용하기도 합니다. 한 번씩 구경해보고 다른 사람들은 어떤 전략으로 성능을 끌어올렸는지 공부해보는 것도 매우 좋을 겁니다!\n",
    "\n",
    "여러 가지 실험을 해보고 결과 csv는 캐글에, 사용한 노트북은 깃허브(GitHub)를 통해 이곳에 제출해 주세요. 제출한 노트북에는 본인의 캐글 Submission 스코어를 기재해 주시기 바랍니다.\n",
    "\n",
    "그럼, 시작해보죠! 화이팅!!! 💪🏼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-mention",
   "metadata": {},
   "source": [
    "### 프로젝트 루브릭\n",
    "\n",
    "---\n",
    "\n",
    "- 데이터 전처리, 모델학습, 예측의 전체 과정을 거쳐 캐글 submission까지 전과정이 성공적으로 진행되었는가?\n",
    "- 제출된 노트북이 캐글 커널로 사용될 수 있을 만큼 전처리, 학습, 최적화 진행 과정이 체계적으로 기술되었는가?\n",
    "- 다양한 피처 엔지니어링과 하이퍼 파라미터 튜닝 등의 최적화 기법을 통해 캐글 리더보드의 Private score 기준 110000 이하의 점수를 얻었는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-comfort",
   "metadata": {},
   "source": [
    "### 루브릭\n",
    "\n",
    "아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
    "\n",
    "|평가문항|상세기준|\n",
    "|:---|:---|\n",
    "|1. 캐글 데이터분석 전과정이 성공적으로 진행되었는가?|데이터 전처리, 모델학습, 예측의 전체 과정을 거쳐 캐글 submission까지 진행되었다.|\n",
    "|2. 전처리, 학습과정 및 결과에 대한 설명이 시각화를 포함하여 체계적으로 진행되었는가?|제출된 노트북이 캐글 커널로 사용될 수 있을 만큼 전처리, 학습, 최적화 진행 과정이 체계적으로 기술되었다.|\n",
    "|3. 회귀모델 예측정확도가 기준 이상 높게 나왔는가?|다양한 피처 엔지니어링과 하이퍼 파라미터 튜닝 등의 최적화 기법을 통해 캐글 리더보드의 Private score 기준 110000 이하의 점수를 얻었다.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-anatomy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
