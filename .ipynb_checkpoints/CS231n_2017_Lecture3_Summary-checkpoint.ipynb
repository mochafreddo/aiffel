{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3. Loss Functions and Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Loss Function\n",
    "\n",
    "- 손실함수 : 임의의 값 $W$를 입력받아 각 스코어를 확인하고 $W$의 기능을 정량화시킨다.\n",
    "- 최적화 : 행렬 $W$가 될 수 있는 모든 경우의 수에 대해 \"가장 덜 구린\" $W$가 무엇인지를 찾는 것.\n",
    "\n",
    "$$L=\\frac{1}{N}\\sum_{i}L_i(f(x_i,W),y_i)$$\n",
    "\n",
    "- $L_i$ : 예측함수 f와 정답 값 y를 입력으로 받아서 이 트레이닝 샘플을 얼마나 구리게 예측하는지를 정량화 시켜준다.\n",
    "- $L$ : 우리 데이터셋에서 각 N개의 샘플 Loss의 평균이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Multiclass SVM loss\n",
    "<br>\n",
    "multi-class SVM은 여러 클래스를 다루기 위한 이진 SVM의 일반화된 형태.<br>\n",
    "(이진 SVM은 두 개의 클래스만 다룬다. 각 데이터는 Positive 또는 Negative로 분류될 뿐.)\n",
    "\n",
    "- Given an example $(x_i,y_i)$   \n",
    "where $x_i$ is the image and   \n",
    "whrer $y_i$ is the (integer) label,   \n",
    "<br><br>\n",
    "- and using the shorthand for the scores vector : $s=f(x_i,W)$   \n",
    "<br><br>\n",
    "- the SVM loss has the form (safety margin = 1) : $\n",
    "\\begin{align}\n",
    "L_i & = \\sum_{j\\neq y_i} \n",
    "\\begin{cases}\n",
    "0, & \\text{if }s_{yi}\\geqq s_j+1 \\\\\n",
    "s_j-s_{yi}+1, & \\text{otherwise}\n",
    "\\end{cases} \\\\\n",
    "& = \\sum_{j \\neq y_i} max(0,s_j-s_{yi}+1) \\\\\n",
    "& \\text{(그래프 모양 때문에 hinge loss라고 부르기도 한다.)} \\\\\n",
    "\\end{align}\n",
    "$<br><br>\n",
    "- Loss over full dataset is average : $L= \\frac{1}{N} \\textstyle \\sum_{i=1}^N L_i$<br><br>\n",
    "사실 손실함수의 스코어가 정확이 몇인지는 신경쓰지 않는다.   \n",
    "궁금한 것은 여러 스코어 간의 **\"상대적인 차이\"**. 우리가 관심있는 것은 오로지 정답 스코어가 다른 스코어에 비해 얼마나 더 큰 스코어를 가지고 있는지 이다.<br><br>\n",
    "- Example code :\n",
    "```\n",
    "def L_i_vectorized(x, y, W):\n",
    "    scores = W.dot(x)\n",
    "    margins = np.maximum(0, scores - scores[y] + 1)\n",
    "    margins[y] = 0\n",
    "    loss_i = np.sum(margins)\n",
    "    return loss_i\n",
    "```\n",
    "\n",
    "> $\n",
    "f(x,W)=Wx \\\\\n",
    "L=\\frac{1}{N}\\sum_{i=1}^N\\sum_{j\\neq{y_i}}max(0,f(x_i;W)_j-f(x_i,;W)_{y_i}+1)\n",
    "$<br>\n",
    "**E.g. Suppose that we found a W such that L = 0.   \n",
    "Is this W unique?**   \n",
    "No! 2W is also has L = 0!\n",
    "\n",
    "> 우리는 트레이닝 데이터에 얼마나 꼭 맞는지는 전혀 신경쓰지 않는다. 기계학습의 핵심은, 트레이닝 데이터를 이용해서 어떤 분류기를 찾는 것인데 그 분류기는 **테스트 데이터**에 적용할 것이기 때문. 그러니 우리는 트레이닝 데이터의 성능에 관심이 있는 것이 아니라 테스트 데이터에서의 성능에 관심이 있는 것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Regularization\n",
    "<br>\n",
    "$$L(W)=\\underbrace{\\frac{1}{N}\\sum_{i=1}^N L_i(f(x_i,W),y_i)}_{\\text{Data loss}}\\underbrace{+\\lambda R(W)}_{Regularization}$$\n",
    "- **Data loss** : Model predictionis should match training data\n",
    "- **Regularization** : Model should be \"simple\", so it works on test data\n",
    "\n",
    "\"Data Loss Term\"에서는 분류기가 트레이닝 데이터에 핏하게 하고,   \n",
    "손실함수에 \"Regularization term\"을 추가해 모델이 좀더 단순한 W를 선택하도록 도와준다.\n",
    "<br><br>\n",
    "\"단순하다\"라는 개념은 우리가 해결해야할 문제나 모델에 따라 조금씩 달라진다.\n",
    "<br>\n",
    ">**Occam's Razor** :   \n",
    "\"Among competing hypotheses, the simplest is the best\"   \n",
    "William of Ockham, 1285~1347   \n",
    "\n",
    "만약 다양한 가설을 가지고 있고, 그 가설 모두가 어떤 현상에 대해 설명이 가능하다면 일반적으로 \"더 단순한 것\"을 선호해야 한다는 것.  \n",
    "왜냐하면 \"더 단순한\" 것이 미래에 일어날 현상을 더 잘 설명할 가능성이 더 높기 때문.  \n",
    "그리고 기계학습에서는 이런 류의 직관을 사용하기 위해 **\"Regularization penalty\"** 라는 것을 만들어 냈다.  \n",
    "Regularization은 보통 **R**로 표기.  \n",
    "\n",
    "그렇게 되면, 일반적인 손실함수의 형태는 두 가지 항을 가지게 된다. **Data loss**와 **Regularization loss**.<br> \n",
    "하이퍼파라미터인 **람다(lambda)** 도 생겼다. *(실제로 모델을 훈련시킬 때 고려해야할 중요한 요소 중 하나)*  \n",
    "\n",
    "- Regularization의 두 가지 역할에 대해 생각해볼 수 있다.\n",
    "    1. 모델이 더 복잡해지지 못하도록 하는 것\n",
    "    2. 모델에 soft penalty를 추가하는 것\n",
    "<br><br>\n",
    "- Regularization의 종류<br><br>\n",
    "    - L2 regularization (또는 Weight decay) (가장 보편적)\n",
    "        - 가중치 행렬 W에 대한 Euclidean Norm (간혹 squared norm)\n",
    "        - 또는 1 / 2 * squared norm을 사용하기도 한다. 미분이 더 깔끔해진다.\n",
    "        - 주요 아이디어 : 가중치 행렬 W의 euclidean norm에 패널티를 주는 것.<br><br>\n",
    "    - L1 regularization\n",
    "        - L1 norm으로 W에 패널티를 부과하는 것.\n",
    "        - 행렬 W가 희소행렬이 되도록 한다.<br><br>\n",
    "    - Elastic net regularization (L1 + L2)<br><br>\n",
    "    - Max norm regularization\n",
    "        - L1, L2 대신 max norm 사용.<br><br>\n",
    "    - Dropout\n",
    "    - Batch normalization\n",
    "    - Stochastic depth<br>\n",
    "\n",
    "Regularization은 딥러닝 외에 많은 기계학습 분야를 통틀어 자주 사용한다. 심지어 더 광범위하게 최적화할 수도 있다.  \n",
    "Regularization은 모델이 트레이닝 데이터셋에 완벽히 핏하지 못하도록 모델의 복잡도에 패널티를 부여하는 방법.<br><br>\n",
    "- example<br><br>\n",
    "    - $x=\\begin{bmatrix}1&1&1&1\\end{bmatrix}$\n",
    "    - $w_1=\\begin{bmatrix}1&0&0&0\\end{bmatrix}$\n",
    "    - $w_2=\\begin{bmatrix}0.25&0.25&0.25&0.25\\end{bmatrix}$<br><br>\n",
    "    - Linear classification : $w_1^T\\cdot x=w_2^T\\cdot x=1$\n",
    "        - Linear classification의 관점에서 $w_1$과 $w_2$는 같다. $x$와의 내적이 서로 같기 때문.<br><br>\n",
    "    - L2 Regularization (Weight Decay)\n",
    "        - $R(W)=\\sum_k\\sum_l W_{k,l}^2$\n",
    "        - L2 Regression은 $w_2$를 더 선호. L2 Regression에서는 $w_2$가 더 norm이 작기 때문.  \n",
    "    L2 Regression은 분류기의 복잡도를 상대적으로 $w_1$과 $w_2$ 중 어떤 것이 더 coarse(조잡)한가 측정한다. (값이 매끄러워야함.)  \n",
    "    Linear classification에서 W가 의미하는 것은 \"얼마나 $x$가 output class와 닮았는지\" 이다.  \n",
    "    L2 Regularization이 말하고자 하는 것은 $x$의 모든 요소가 영향을 줬으면 하는 것.  \n",
    "    그러니 변동이 심한 어떤 입력 $x$가 있고 그 $x$의 특정 요소에만 의존하기보다 모든 $x$의 요소가 골고루 영향을 미치길 원한다면 L2 Regulariztion을 통해 더 강인해질 수 있을 것.\n",
    "        - L2의 경우에는 $w$의 요소가 전체적으로 퍼져있을 때 \"덜 복잡하다\"라고 생각한다.<br><br>\n",
    "    - L1 Regularization\n",
    "        - L1 Regularization의 경우에는 정반대. L1 Regularization을 쓰게 되면 $w_2$ 보다 $w_1$을 더 선호.  \n",
    "    L1 Regularization은 \"복잡도\"를 다르게 정의. 가중치 $w$의 0의 갯수에 따라 모델의 복잡도를 다룬다.\n",
    "        - 일반적으로 L1은 sparse한 solutions를 선호한다.  \n",
    "        L1이 \"복잡하다\"고 느끼고 측정하는 것은 0이 아닌 요소들의 갯수.<br><br>\n",
    "    - **\"복잡도\"를 어떻게 정의하느냐, 어떻게 측정하느냐는 우리가 어떤 문제를 가지고 있느냐에 따라 다르다.**  \n",
    "    - If you are a Bayesian: L2 regularization also corresponds MAP inference using a Gaussian prior on W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Softmax Classifier (Multinomial Logistic Regression)\n",
    "\n",
    "사실 딥러닝에서는 이것을 더 많이 사용한다.<br><br>\n",
    "multi-class SVM loss에서 우리는 스코어 자체에 대한 해석은 고려하지 않았다.  \n",
    "단지 정답 클래스가 정답이 아닌 클래스들보다 더 높은 스코어를 내기만 원했다.  \n",
    "하지만 <u>Multinomial Logistic Regression의 손실함수는 스코어 자체에 추가적인 의미를 부여한다.</u><br><br>\n",
    "**score = unnormalized log probabilities of the classes.(클래스의 정규화되지 않은 로그 확률)**<br><br>\n",
    "$$P(Y=k|X=x_i)=\\underbrace{\\frac{e^{s_k}}{\\sum_j e^{s_j}}}_{Softmax function}\\text{ where }s=f(x_i;W)$$<br>\n",
    "위 수식을 이용해 스코어를 가지고 클래스별 확률분포를 계산한다.  \n",
    "스코어를 전부 이용하는데, 스코어들에 지수를 취해 양수가 되게 만든다.  \n",
    "그 지수들의 합으로 다시 정규화시킨다.  \n",
    "그래서 Softmax 함수를 거치게 되면 우리는 결국 **확률분포**를 얻을 수 있고, 그것이 바로 **해당 클래스일 확률**이 되는 것이다.  \n",
    "확률이기 때문에 0에서 1 사이의 값이고, 모든 확률들의 합은 1이 된다.<br><br><br>\n",
    "$$L_i=-\\log P(Y=y_i|X=x_i)$$<br>\n",
    "위는 스코어를 가지고 계산한 확률분포  \n",
    "이런 식은 다양하게 사용될 수 있다. 예를 들어 타겟과 계산된 확률분포 간의 KL divergence 라던가 MLE(maximum likelihood estimate)로 볼 수도 있다.  \n",
    "하지만 결국 원하는 것은 정답 클래스에 해당하는 클래스의 확률이 1에 가깝게 계산되는 것이다.  \n",
    "그렇게 되면 loss는 \"$-\\log(\\text{정답클래스확률})$\"가 될 것이다.<br><br>\n",
    "우리는 지금 확률이 1이 되길 원하고 있다.  \n",
    "그리고 $\\log$는 단조 증가 함수이다.  \n",
    "그리고 $\\log$를 최대화시키는 것이 그냥 확률값을 최대화시키는 것보다 쉽다.\n",
    "그러니 우리는 $\\log$를 쓴다.  \n",
    "정답클래스인 $\\log P$를 최대화시키는건, $\\log P$가 높았으면 좋겠다는 것이다.  \n",
    "그런데 손실함수는 \"얼마나 좋은지\"가 아니라 \"얼마나 구린지\"를 측정하는 것이기 때문에 $\\log$에 마이너스를 붙힌다.  \n",
    "이제 SVM의 손실함수는 $-\\log(P(\\text{정답클래스}))$로 나타내게 된다.<br><br>\n",
    "**in summary:**\n",
    "$$L_i=-\\log\\left(\\frac{e^{s_{y_i}}}{\\sum_{j}e^{s_j}}\\right)$$\n",
    "스코어가 있으면, Softmax를 거치고, 나온 확률 값에 $-\\log$를 취해주면 된다.<br><br>\n",
    "**Q.** What is the min/max possible loss $L_i$(softmax loss)?  \n",
    "**A.** min = 0, max = $\\infty$  \n",
    "컴퓨터는 무한대 계산을 잘 못하기 때문에 Loss가 0인 경우는 절대 없는 것이다. (유한정밀도 때문)  \n",
    "하지만 이론적 해석을 가미하면 0은 \"이론적으로 최소 Loss다\"라고 보면 된다.  \n",
    "최대 손실은 최댓값이 없다.  \n",
    "하지만 이런 경우 또한 발생하지 않을 것이다.  \n",
    "왜냐하면 확률이 0이 되려면 $e^{s_{y_i}}$가 0이 되어야 하는데, 그게 가능한 경우는 정답클래스의 스코어가 음의 무한대일 때 뿐이기 때문이다.  \n",
    "\"유한정밀도\"를 가지고는 최댓값(무한대), 최솟값(0)에 도달할 수 없다.<br><br>\n",
    "**Q.** Usually at initialization $W$ is small so all $s\\approx0$. What is the loss?  \n",
    "**A.** $L_i=-\\log\\left(\\frac{1}{C}\\right)=\\log(C)$  \n",
    "Softmax를 사용할 때 첫 번째 interation에서 해볼만한 아주 좋은 디버깅 전략이다.<br><br>\n",
    "**SVM vs Softmax**  \n",
    "SVM의 경우에는 일정 선(margins)을 넘기만 하면 더이상 성능 개선에 신경쓰지 않는다.  \n",
    "반면 Softmax는 더더더더더 좋게 성능을 높이려 할 것이다.  \n",
    "실제 딥러닝 애플리케이션에서 두 손실함수 간의 성능 차이는 엄청나게 크진 않지만 차이를 알고 있는 것은 유용할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Recap\n",
    "- We have some dataset of $(x,y)$<br><br>\n",
    "- We have a **score function:** $s=f(x;W)\\overset{e.g.}{=}Wx$<br><br>\n",
    "    - 입력 $x$로부터 스코어 $s$를 얻기 위해 Linear Classifier를 사용한다.<br><br>\n",
    "- We have a **loss function:**<br><br>\n",
    "    - Softmax: $L_i=-\\log\\left(\\frac{e^{s_{y_i}}}{\\sum_{j}e^{s_j}}\\right)$<br><br>\n",
    "    - SVM: $L_i=\\sum_{j\\neq{y_i}}\\max(0,s_j-s_{y_i}+1)$<br><br>\n",
    "        - 손실함수를 이용해 모델의 예측값이 정답값에 비해 \"얼마나 구린지\"를 측정한다.<br><br>\n",
    "    - Full loss: $L=\\frac{1}{N}\\sum_{i=1}^{N}L_i+R(W)$<br><br>\n",
    "        - 모델의 \"복잡함\"과 \"단순함\"을 통제하기 위해 손실함수에 Regularization Term을 추가한다.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
