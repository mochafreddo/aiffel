{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spare-photographer",
   "metadata": {},
   "source": [
    "# 19-6. 프로젝트 : Pretrained model의 활용\n",
    "\n",
    "이제 본격적으로 pretrained model을 활용해 보겠습니다. 사용해야 할 모델 구조나 데이터셋 구조, 배치 구조는 이전 스텝과 동일합니다. 다음 안내를 따라 이미 다운로드한 pretrained model을 활용하는 학습을 다시 진행해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-measure",
   "metadata": {},
   "source": [
    "### STEP 1. pretrained model 로딩하기\n",
    "---\n",
    "pretrained model을 로드하여 model을 생성하는 코드는 아래와 같습니다. model 구조는 이전 스텝과 동일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = os.path.join(model_dir, 'bert_pretrain_32000.hdf5')\n",
    "\n",
    "model = BERT4KorQuAD(config)\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    #  pretrained model 을 로드하기 위해 먼저 모델이 생성되어 있어야 한다.\n",
    "    enc_tokens = np.random.randint(0, len(vocab), (4, 10))\n",
    "    segments = np.random.randint(0, 2, (4, 10))\n",
    "    model(enc_tokens, segments)\n",
    "    \n",
    "    # checkpoint 파일로부터 필요한 layer를 불러온다. \n",
    "    model.load_weights(os.path.join(model_dir, \"bert_pretrain_32000.hdf5\"), by_name=True)\n",
    "\n",
    "    model.summary()\n",
    "else:\n",
    "    print('NO Pretrained Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-surname",
   "metadata": {},
   "source": [
    "### STEP 2. pretrained model finetune 하기\n",
    "---\n",
    "학습을 진행하는 코드도 이전 스텝과 동일합니다. 단지 학습해야 할 모델이 랜덤 초기화된 것이 아니라 pretrained model을 로드한 것일 뿐입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-klein",
   "metadata": {},
   "source": [
    "### STEP 3. Inference 수행하기\n",
    "---\n",
    "finetune 학습이 완료된 model을 활용하여 실제 퀴즈 풀이 결과를 확인해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_predict(model, question, context):\n",
    "    \"\"\"\n",
    "    입력에 대한 답변 생성하는 함수\n",
    "    :param model: model\n",
    "    :param question: 입력 문자열\n",
    "    :param context: 입력 문자열\n",
    "    \"\"\"\n",
    "    q_tokens = vocab.encode_as_pieces(question)[:args.max_query_length]\n",
    "    c_tokens = vocab.encode_as_pieces(context)[:args.max_seq_length - len(q_tokens) - 3]\n",
    "    tokens = ['[CLS]'] + q_tokens + ['[SEP]'] + c_tokens + ['[SEP]']\n",
    "    token_ids = [vocab.piece_to_id(token) for token in tokens]\n",
    "    segments = [0] * (len(q_tokens) + 2) + [1] * (len(c_tokens) + 1)\n",
    "\n",
    "    y_start, y_end = model(np.array([token_ids]), np.array([segments]))\n",
    "    # print(y_start, y_end)\n",
    "    y_start_idx = K.argmax(y_start, axis=-1)[0].numpy()\n",
    "    y_end_idx = K.argmax(y_end, axis=-1)[0].numpy()\n",
    "    answer_tokens = tokens[y_start_idx:y_end_idx + 1]\n",
    "\n",
    "    return vocab.decode_pieces(answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_json = os.path.join(data_dir, \"korquad_dev.json\")\n",
    "\n",
    "with open(dev_json) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        data = json.loads(line)\n",
    "        question = vocab.decode_pieces(data['question'])\n",
    "        context = vocab.decode_pieces(data['context'])\n",
    "        answer = data['answer']\n",
    "        answer_predict = do_predict(model, question, context)\n",
    "        if answer in answer_predict:\n",
    "            print(i)\n",
    "            print(\"질문 : \", question)\n",
    "            print(\"지문 : \", context)\n",
    "            print(\"정답 : \", answer)\n",
    "            print(\"예측 : \", answer_predict, \"\\n\")\n",
    "        if 100 < i:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-stone",
   "metadata": {},
   "source": [
    "### STEP 4. 학습 경과 시각화 비교분석\n",
    "---\n",
    "pretrained model 사용 여부에 따라 학습 수행 경과가 어떻게 달라지는지를 시각화를 포함하여 비교분석을 진행해 봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-salon",
   "metadata": {},
   "source": [
    "### 루브릭\n",
    "---\n",
    "아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
    "\n",
    "|평가문항|상세기준|\n",
    "|:---|:---|\n",
    "|1. BERT pretrained model을 활용한 KorQuAD 모델이 정상적으로 학습이 진행되었다.|KorQuAD 모델의 validation accuracy가 안정적으로 증가하였다.|\n",
    "|2. KorQuAD Inference 결과가 원래의 정답과 비교하여 유사하게 나오는 것을 확인하였다.|평가셋에 대해 모델 추론 결과와 실제 정답의 유사성이 확인되었다.|\n",
    "|3. pretrained model 활용이 효과적임을 실험을 통해 확인하였다.|pretrained model을 사용하지 않았을 때 대비 학습경과의 차이를 시각화를 통해 확인하였다.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-briefing",
   "metadata": {},
   "source": [
    "### Postscript\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-lounge",
   "metadata": {},
   "source": [
    "### Reference\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
