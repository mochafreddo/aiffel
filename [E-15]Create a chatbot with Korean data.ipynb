{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "formed-session",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#15-14.-프로젝트:-한국어-데이터로-챗봇-만들기\" data-toc-modified-id=\"15-14.-프로젝트:-한국어-데이터로-챗봇-만들기-1\">15-14. 프로젝트: 한국어 데이터로 챗봇 만들기</a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-1.-데이터-수집하기\" data-toc-modified-id=\"Step-1.-데이터-수집하기-1.1\">Step 1. 데이터 수집하기</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-data\" data-toc-modified-id=\"Loading-data-1.1.1\">Loading data</a></span></li><li><span><a href=\"#Checking-for-missing-values\" data-toc-modified-id=\"Checking-for-missing-values-1.1.2\">Checking for missing values</a></span></li></ul></li><li><span><a href=\"#Step-2.-데이터-전처리하기\" data-toc-modified-id=\"Step-2.-데이터-전처리하기-1.2\">Step 2. 데이터 전처리하기</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing-function\" data-toc-modified-id=\"Preprocessing-function-1.2.1\">Preprocessing function</a></span></li></ul></li><li><span><a href=\"#Step-3.-SubwordTextEncoder-사용하기\" data-toc-modified-id=\"Step-3.-SubwordTextEncoder-사용하기-1.3\">Step 3. SubwordTextEncoder 사용하기</a></span><ul class=\"toc-item\"><li><span><a href=\"#SubwordTextEncoder\" data-toc-modified-id=\"SubwordTextEncoder-1.3.1\">SubwordTextEncoder</a></span></li><li><span><a href=\"#START_TOKEN,-END_TOKEN,-VOCAB_SIZE\" data-toc-modified-id=\"START_TOKEN,-END_TOKEN,-VOCAB_SIZE-1.3.2\">START_TOKEN, END_TOKEN, VOCAB_SIZE</a></span></li><li><span><a href=\"#전체-데이터에-대해-정수인코딩과-패딩을-진행\" data-toc-modified-id=\"전체-데이터에-대해-정수인코딩과-패딩을-진행-1.3.3\">전체 데이터에 대해 정수인코딩과 패딩을 진행</a></span></li><li><span><a href=\"#인코더와-디코더의-입력,-레이블-만들기\" data-toc-modified-id=\"인코더와-디코더의-입력,-레이블-만들기-1.3.4\">인코더와 디코더의 입력, 레이블 만들기</a></span></li></ul></li><li><span><a href=\"#Step-4.-모델-구성하기\" data-toc-modified-id=\"Step-4.-모델-구성하기-1.4\">Step 4. 모델 구성하기</a></span><ul class=\"toc-item\"><li><span><a href=\"#PositionalEncoding()\" data-toc-modified-id=\"PositionalEncoding()-1.4.1\">PositionalEncoding()</a></span></li><li><span><a href=\"#scaled_dot_product_attention()\" data-toc-modified-id=\"scaled_dot_product_attention()-1.4.2\">scaled_dot_product_attention()</a></span></li><li><span><a href=\"#MultiHeadAttention()\" data-toc-modified-id=\"MultiHeadAttention()-1.4.3\">MultiHeadAttention()</a></span></li><li><span><a href=\"#create_padding_make()\" data-toc-modified-id=\"create_padding_make()-1.4.4\">create_padding_make()</a></span></li><li><span><a href=\"#create_look_ahead_mask()\" data-toc-modified-id=\"create_look_ahead_mask()-1.4.5\">create_look_ahead_mask()</a></span></li><li><span><a href=\"#encoder_layer()\" data-toc-modified-id=\"encoder_layer()-1.4.6\">encoder_layer()</a></span></li><li><span><a href=\"#encoder()\" data-toc-modified-id=\"encoder()-1.4.7\">encoder()</a></span></li><li><span><a href=\"#decoder_layer()\" data-toc-modified-id=\"decoder_layer()-1.4.8\">decoder_layer()</a></span></li><li><span><a href=\"#decoder()\" data-toc-modified-id=\"decoder()-1.4.9\">decoder()</a></span></li><li><span><a href=\"#trainsformer()\" data-toc-modified-id=\"trainsformer()-1.4.10\">trainsformer()</a></span></li><li><span><a href=\"#Hyper-parameter\" data-toc-modified-id=\"Hyper-parameter-1.4.11\">Hyper parameter</a></span></li><li><span><a href=\"#Loss-function\" data-toc-modified-id=\"Loss-function-1.4.12\">Loss function</a></span></li><li><span><a href=\"#Custom-Learning-rate-Scheduling\" data-toc-modified-id=\"Custom-Learning-rate-Scheduling-1.4.13\">Custom Learning rate Scheduling</a></span></li><li><span><a href=\"#Compile\" data-toc-modified-id=\"Compile-1.4.14\">Compile</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-1.4.15\">Training</a></span></li></ul></li><li><span><a href=\"#Step-5.-모델-평가하기\" data-toc-modified-id=\"Step-5.-모델-평가하기-1.5\">Step 5. 모델 평가하기</a></span></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-1.6\">Conclusion</a></span></li><li><span><a href=\"#Postscript\" data-toc-modified-id=\"Postscript-1.7\">Postscript</a></span></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-1.8\">Reference</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-holly",
   "metadata": {},
   "source": [
    "# 15-14. 프로젝트: 한국어 데이터로 챗봇 만들기\n",
    "\n",
    "영어로 만들었던 챗봇을 한국어 데이터로 바꿔서 훈련시켜봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sorted-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "virgin-sweet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-ferry",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 수집하기\n",
    "---\n",
    "한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용합니다.\n",
    "\n",
    "이 데이터는 아래의 링크에서 다운로드할 수 있습니다.\n",
    "\n",
    "- [songys/Chatbot_data](https://github.com/songys/Chatbot_data/blob/master/ChatbotData%20.csv)\n",
    "\n",
    "```\n",
    "wget으로 데이터 다운로드\n",
    "$ wget https://github.com/songys/Chatbot_data/raw/master/ChatbotData%20.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-stand",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incredible-providence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = os.path.join(os.getenv('HOME'), 'aiffel/songys_chatbot/ChatbotData .csv')\n",
    "train_data = pd.read_csv(filepath)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-payday",
   "metadata": {},
   "source": [
    "### Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cutting-museum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q        0\n",
       "A        0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-envelope",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 전처리하기\n",
    "---\n",
    "영어 데이터와는 전혀 다른 데이터인 만큼 영어 데이터에 사용했던 전처리와 일부 동일한 전처리도 필요하겠지만 전체적으로는 다른 전처리를 수행해야 할 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-medicaid",
   "metadata": {},
   "source": [
    "### Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "enormous-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \"\"\"\n",
    "    Preprocessing function.\n",
    "    Make the distance between words and punctuation marks.\n",
    "    \"\"\"\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "median-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [preprocess_sentence(sentence) for sentence in train_data['Q']]\n",
    "answers = [preprocess_sentence(sentence) for sentence in train_data['A']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "optional-blind",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-australian",
   "metadata": {},
   "source": [
    "## Step 3. SubwordTextEncoder 사용하기\n",
    "---\n",
    "한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다고 많은 분이 알고 있습니다. 하지만 여기서는 형태소 분석기가 아닌 위 실습에서 사용했던 내부 단어 토크나이저인 `SubwordTextEncoder`를 그대로 사용해보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-audience",
   "metadata": {},
   "source": [
    "### SubwordTextEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "genuine-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubwordTextEncoder를 사용하여 질문, 답변 데이터로부터 단어집합 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-fiction",
   "metadata": {},
   "source": [
    "### START_TOKEN, END_TOKEN, VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prompt-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size+1]\n",
    "VOCAB_SIZE = tokenizer.vocab_size+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "quantitative-trinidad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN: [8178]\n",
      "END_TOKEN: [8179]\n",
      "VOCAB_SIZE: 8180\n"
     ]
    }
   ],
   "source": [
    "print(f'START_TOKEN: {START_TOKEN}')\n",
    "print(f'END_TOKEN: {END_TOKEN}')\n",
    "print(f'VOCAB_SIZE: {VOCAB_SIZE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-engagement",
   "metadata": {},
   "source": [
    "### 전체 데이터에 대해 정수인코딩과 패딩을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deadly-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "established-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_filter(inputs, outputs):\n",
    "    \"\"\"\n",
    "    Integer encoding,\n",
    "    removing samples exceeding maximum length,\n",
    "    padding\n",
    "    \"\"\"\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "\n",
    "    # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "parental-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "imported-thousand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions.shape: (11823, 40)\n",
      "answers.shape: (11823, 40)\n"
     ]
    }
   ],
   "source": [
    "print(f'questions.shape: {questions.shape}')\n",
    "print(f'answers.shape: {answers.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-class",
   "metadata": {},
   "source": [
    "### 인코더와 디코더의 입력, 레이블 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "satisfactory-diesel",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {'inputs': questions,\n",
    "     'dec_inputs': answers[:, :-1]},  # 디코더의 입력\n",
    "    {'outputs': answers[:, 1:]},      # 시작 토큰 제거\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-truck",
   "metadata": {},
   "source": [
    "## Step 4. 모델 구성하기\n",
    "---\n",
    "위 실습 내용을 참고하여 트랜스포머 모델을 구현합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-jersey",
   "metadata": {},
   "source": [
    "### PositionalEncoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "analyzed-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) /\n",
    "                            tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스(2i)에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "\n",
    "        # 배열의 홀수 인덱스(2i+1)에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-strap",
   "metadata": {},
   "source": [
    "### scaled_dot_product_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "collected-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    \"\"\"Calculate the attention weight.\"\"\"\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # add the mask to zero out padding tokens\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-ranking",
   "metadata": {},
   "source": [
    "### MultiHeadAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "modular-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # linear layers\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다.\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(\n",
    "            query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다.\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # final linear layer\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-franklin",
   "metadata": {},
   "source": [
    "### create_padding_make()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "manufactured-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-discussion",
   "metadata": {},
   "source": [
    "### create_look_ahead_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "recreational-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - \\\n",
    "        tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-principle",
   "metadata": {},
   "source": [
    "### encoder_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "grateful-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-somalia",
   "metadata": {},
   "source": [
    "### encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bulgarian-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-commodity",
   "metadata": {},
   "source": [
    "### decoder_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cognitive-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': look_ahead_mask\n",
    "        })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1,\n",
    "            'key': enc_outputs,\n",
    "            'value': enc_outputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-transformation",
   "metadata": {},
   "source": [
    "### decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "silver-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-classroom",
   "metadata": {},
   "source": [
    "### trainsformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "limiting-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    \"\"\"\n",
    "    TRANSFORMER\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask,\n",
    "        output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask,\n",
    "        output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(\n",
    "        units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-jordan",
   "metadata": {},
   "source": [
    "### Hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "antique-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 6  # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 512  # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8  # 멀티 헤드 어텐션에서의 헤드 수\n",
    "UNITS = 2048  # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1  # 드롭아웃의 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-employee",
   "metadata": {},
   "source": [
    "나는 논문과 똑같이 해보겠다는 패기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "confirmed-movie",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method PositionalEncoding.call of <__main__.PositionalEncoding object at 0x7f39c459f490>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method PositionalEncoding.call of <__main__.PositionalEncoding object at 0x7f39c459f490>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method PositionalEncoding.call of <__main__.PositionalEncoding object at 0x7f39c459f490>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x7f39c47a7a10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x7f39c47a7a10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x7f39c47a7a10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 512)    23102464    inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 512)    29412352    dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8180)   4196340     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 56,711,156\n",
      "Trainable params: 56,711,156\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = transformer(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        units=UNITS,\n",
    "        d_model=D_MODEL,\n",
    "        num_heads=NUM_HEADS,\n",
    "        dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-bidding",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "judicial-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-omega",
   "metadata": {},
   "source": [
    "### Custom Learning rate Scheduling\n",
    "\n",
    "$lrate = d_{model}^{-0.5} \\cdot min(step\\_num^{-0.5}, step\\_num \\cdot warmup\\_steps^{-1.5})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "romantic-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-organic",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "exposed-policy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "with strategy.scope():\n",
    "    model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-playing",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "empirical-developer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "INFO:tensorflow:batch_all_reduce: 254 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 254 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 254 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 254 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 56s 118ms/step - loss: 1.4477 - accuracy: 0.0180\n",
      "Epoch 2/50\n",
      "185/185 [==============================] - 22s 121ms/step - loss: 1.1016 - accuracy: 0.0496\n",
      "Epoch 3/50\n",
      "185/185 [==============================] - 22s 121ms/step - loss: 0.9846 - accuracy: 0.0508\n",
      "Epoch 4/50\n",
      "185/185 [==============================] - 23s 122ms/step - loss: 0.9451 - accuracy: 0.0530\n",
      "Epoch 5/50\n",
      "185/185 [==============================] - 23s 126ms/step - loss: 0.8975 - accuracy: 0.0555\n",
      "Epoch 6/50\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.8515 - accuracy: 0.0580\n",
      "Epoch 7/50\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 0.8089 - accuracy: 0.0606\n",
      "Epoch 8/50\n",
      "185/185 [==============================] - 24s 130ms/step - loss: 0.7556 - accuracy: 0.0643\n",
      "Epoch 9/50\n",
      "185/185 [==============================] - 24s 131ms/step - loss: 0.7039 - accuracy: 0.0689\n",
      "Epoch 10/50\n",
      "185/185 [==============================] - 24s 131ms/step - loss: 0.6414 - accuracy: 0.0759\n",
      "Epoch 11/50\n",
      "185/185 [==============================] - 24s 132ms/step - loss: 0.5799 - accuracy: 0.0823\n",
      "Epoch 12/50\n",
      "185/185 [==============================] - 24s 131ms/step - loss: 0.5222 - accuracy: 0.0892\n",
      "Epoch 13/50\n",
      "185/185 [==============================] - 24s 131ms/step - loss: 0.4651 - accuracy: 0.0973\n",
      "Epoch 14/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.4137 - accuracy: 0.1047\n",
      "Epoch 15/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.3710 - accuracy: 0.1101\n",
      "Epoch 16/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.3454 - accuracy: 0.1147\n",
      "Epoch 17/50\n",
      "185/185 [==============================] - 24s 132ms/step - loss: 0.3178 - accuracy: 0.1171\n",
      "Epoch 18/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.3040 - accuracy: 0.1197\n",
      "Epoch 19/50\n",
      "185/185 [==============================] - 24s 132ms/step - loss: 0.2935 - accuracy: 0.1219\n",
      "Epoch 20/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.2863 - accuracy: 0.1221\n",
      "Epoch 21/50\n",
      "185/185 [==============================] - 25s 132ms/step - loss: 0.2806 - accuracy: 0.1228\n",
      "Epoch 22/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.2780 - accuracy: 0.1240\n",
      "Epoch 23/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.2713 - accuracy: 0.1248\n",
      "Epoch 24/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.2600 - accuracy: 0.1255\n",
      "Epoch 25/50\n",
      "185/185 [==============================] - 24s 132ms/step - loss: 0.2523 - accuracy: 0.1267\n",
      "Epoch 26/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.2439 - accuracy: 0.1293\n",
      "Epoch 27/50\n",
      "185/185 [==============================] - 24s 132ms/step - loss: 0.2387 - accuracy: 0.1304\n",
      "Epoch 28/50\n",
      "185/185 [==============================] - 25s 132ms/step - loss: 0.2328 - accuracy: 0.1316\n",
      "Epoch 29/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.2279 - accuracy: 0.1323\n",
      "Epoch 30/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.2236 - accuracy: 0.1319\n",
      "Epoch 31/50\n",
      "185/185 [==============================] - 25s 132ms/step - loss: 0.2212 - accuracy: 0.1319\n",
      "Epoch 32/50\n",
      "185/185 [==============================] - 24s 132ms/step - loss: 0.2164 - accuracy: 0.1338\n",
      "Epoch 33/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.2122 - accuracy: 0.1346\n",
      "Epoch 34/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.2107 - accuracy: 0.1341\n",
      "Epoch 35/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.2063 - accuracy: 0.1340\n",
      "Epoch 36/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.2037 - accuracy: 0.1363\n",
      "Epoch 37/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.2004 - accuracy: 0.1358\n",
      "Epoch 38/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.1983 - accuracy: 0.1358\n",
      "Epoch 39/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.1953 - accuracy: 0.1378\n",
      "Epoch 40/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.1927 - accuracy: 0.1372\n",
      "Epoch 41/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.1913 - accuracy: 0.1371\n",
      "Epoch 42/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.1893 - accuracy: 0.1376\n",
      "Epoch 43/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.1875 - accuracy: 0.1380\n",
      "Epoch 44/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.1862 - accuracy: 0.1389\n",
      "Epoch 45/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.1850 - accuracy: 0.1385\n",
      "Epoch 46/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.1837 - accuracy: 0.1386\n",
      "Epoch 47/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.1813 - accuracy: 0.1386\n",
      "Epoch 48/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.1801 - accuracy: 0.1394\n",
      "Epoch 49/50\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.1786 - accuracy: 0.1392\n",
      "Epoch 50/50\n",
      "185/185 [==============================] - 24s 132ms/step - loss: 0.1773 - accuracy: 0.1407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f39741e4550>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-queensland",
   "metadata": {},
   "source": [
    "## Step 5. 모델 평가하기\n",
    "---\n",
    "Step 1에서 선택한 전처리 방법을 고려하여 입력된 문장에 대해서 대답을 얻는 예측 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "derived-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "    # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "above-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "weekly-harmony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 누구냐 넌?!\n",
      "출력 : 그럴 수 있을 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'그럴 수 있을 거예요 .'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('누구냐 넌?!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "equivalent-intent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 커피는 역시 모닝커피지.\n",
      "출력 : 좋은 시간 보내고 있나봐요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 시간 보내고 있나봐요 .'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('커피는 역시 모닝커피지.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ordinary-hospital",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 여행가고 싶다.\n",
      "출력 : 오늘 피크닉 가기 좋은 날이에요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'오늘 피크닉 가기 좋은 날이에요 .'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('여행가고 싶다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "distributed-sending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 내일 날씨는 어떨 것 같아?\n",
      "출력 : 저는 둘이 가는 게 좋아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저는 둘이 가는 게 좋아요 .'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('내일 날씨는 어떨 것 같아?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "returning-family",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 야식으로 뭐 먹을까?\n",
      "출력 : 당신이라면 충분히 극복할 수 있어요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'당신이라면 충분히 극복할 수 있어요 .'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('야식으로 뭐 먹을까?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "previous-aurora",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 좋아하는 색은?\n",
      "출력 : 내가 결혼할 때가 결혼적령기예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'내가 결혼할 때가 결혼적령기예요 .'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('좋아하는 색은?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "common-republic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 주말에 같이 드라이브 갈래?\n",
      "출력 : 혼자 사는 것보다 불편하겠죠 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'혼자 사는 것보다 불편하겠죠 .'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('주말에 같이 드라이브 갈래?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "official-isaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너 자꾸 헛소리 할래?\n",
      "출력 : 내가 우선순위면 돼요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'내가 우선순위면 돼요 .'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('너 자꾸 헛소리 할래?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "environmental-uncertainty",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 이기적이구나?\n",
      "출력 : 그게 진짜 사랑이네요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'그게 진짜 사랑이네요 .'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('이기적이구나?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "soviet-evidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 네가 사랑을 알아?\n",
      "출력 : 제가 있잖아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'제가 있잖아요 .'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('네가 사랑을 알아?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "posted-cisco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 그만하자. 오늘은 여기까지.\n",
      "출력 : 더 좋은 곳에서 살 수 있을 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'더 좋은 곳에서 살 수 있을 거예요 .'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('그만하자. 오늘은 여기까지.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "thorough-cambridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 싸우자!\n",
      "출력 : 같이 가는 여행도 좋지만 혼자 여행도 좋을 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'같이 가는 여행도 좋지만 혼자 여행도 좋을 거예요 .'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('싸우자!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-western",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "---\n",
    "- 한국어 전처리를 통해 학습 데이터셋을 구축하였다.  \n",
    "    - 공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.\n",
    "\n",
    "- 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.  \n",
    "    - 구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.\n",
    "\n",
    "- 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.  \n",
    "    - 한국어 입력문장에 그럴듯한 한국어로 답변을 리턴하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-market",
   "metadata": {},
   "source": [
    "## Postscript\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-kernel",
   "metadata": {},
   "source": [
    "- 논문과 같은 하이퍼 파라미터를 적용하면 더 똑똑하게 답변할 줄 알았는데, 생각보다 엉뚱한 소리를 많이 합니다. 역시 중요한 것은 학습 데이터인가 봅니다.\n",
    "- 이미 공개된 코드가 있어 구현에는 전혀 어려움이 없었습니다.\n",
    "- 새로운 모델에 대한 공부를 할 수 있는 좋은 시간이었습니다.\n",
    "- 이번 실습을 통해 자연어처리에 대한 흥미가 생겼습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-cincinnati",
   "metadata": {},
   "source": [
    "## Reference\n",
    "---\n",
    "- [2) 트랜스포머를 이용한 한국어 챗봇(Transformer Chatbot Tutorial) - 딥 러닝을 이용한 자연어 처리 입문](https://wikidocs.net/89786)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
